#!/usr/bin/env ruby

require 'rubygems'
require 'commander/import'
require 'scraper'
require 'terminal-table'
require 'twitter_client'
require 'awl_tags_twitter/version'

program :version, AwlTagsTwitter::VERSION
program :description, 'Grab tags from posts and tweet them out'

command :list do |c|
  c.syntax = 'awl_tags_twitter list'
  c.summary = 'List current posts and their tags'
  c.description = 'List current posts and their tags. Display them'\
                  ' in an ASCII table split as they would be tweeted'
  c.example 'basic', 'awl_tags_twitter list --basic'
  c.example 'complex', 'awl_tags_twitter list --complex'
  c.option '--basic', 'Display posts with tags'
  c.option '--complex', 'Display posts with tags split between posts'
  c.action do |_args, options|
    scraper = Scraper.new
    scraper.retrieve_posts
    if options.basic
      scraper.subtract_cache
      rows = scraper.articles.map { |a| [a.link, a.tags] }
    elsif options.complex
      scraper.subtract_cache
      scraper.articles.map(&:build_tweets)
      rows = scraper.articles.map { |a| [a.link, a.tags, a.tweets] }
    else
      fail 'provide --basic or --complex'
    end
    tracker = Tracker.new
    tracker.read_articles
    tracker.articles << scraper.articles.map(&:link)
    tracker.articles.flatten!
    tracker.write_articles

    table = Terminal::Table.new rows: rows
    puts table
  end
end

command :'cache-all' do |c|
  c.syntax = 'awl_tags_twitter cache-all [options]'
  c.summary = 'Cache all existing articles'
  c.description = 'This method will call the AWL and save all files to disk.'\
  'You can use this if there is an issue while attempting to publish a tweet.'
  c.example 'default', 'awl_tags_twitter cache-all'
  c.example 'dry-run', 'awl_tags_twitter cache-all --dry-run'
  c.option '--dry', 'Print which articles would get saved, but don\'t save them'
  c.action do |_args, options|
    scraper = Scraper.new
    scraper.retrieve_posts
    scraper.subtract_cache
    rows = scraper.articles.map { |a| [a.link, a.tags] }
    tracker = Tracker.new
    tracker.read_articles
    tracker.articles << scraper.articles.map(&:link)
    tracker.articles.flatten!
    tracker.write_articles unless options.dry

    table = Terminal::Table.new rows: rows
    puts table
  end
end

command :tweet do |c|
  c.syntax = 'awl_tags_twitter tweet'
  c.summary = 'tweet out any untweeted post.'
  c.description = 'Grabs a list of all the posts which haven\'t been tweeted' \
                   'then builds the tweets, and tweets them for you'
  c.example 'default', 'awl_tags_twitter tweet'
  c.example 'dry', 'awl_tags_twitter tweet --dry'
  c.option '--dry', 'Display what tweets would be sent out'
  c.option '--config STRING', 'Path to the configuration file'
  c.action do |_args, options|
    credentials = JSON.parse(File.read(options.config))
    twitter_client = TwitterClient.new(credentials)
    fail 'please pass a configuration file' unless options.config
    p "loading with Config #{options.config}"
    scraper = Scraper.new
    scraper.retrieve_posts
    scraper.subtract_cache
    scraper.articles.map(&:build_tweets)
    tracker = Tracker.new
    tracker.read_articles
    tracker.articles << scraper.articles.map(&:link)
    tracker.articles.flatten!
    rows = scraper.articles.map { |a| [a.tweets] }

    unless options.dry
      scraper.articles.each do |a|
        a.tweets.each do |t|
          twitter_client.update(t)
        end
      end

      # push out them tweets
      # tracker.write_articles
    end

    table = Terminal::Table.new rows: rows
    puts table
  end
end
